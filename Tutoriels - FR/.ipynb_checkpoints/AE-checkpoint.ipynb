{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions utilitaires random en attendant de voir que ça existe dans numpy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top(vector, maximum, k):        \n",
    "    c = maximum * np.argsort(scores)[-k:] + (1 - maximum) * np.argsort(scores)[:k]\n",
    "    d = []\n",
    "    for i in np.arange(len(c)):\n",
    "        d.append(vector[c[i]])\n",
    "    return d\n",
    "\n",
    "def rearrange(items, ratings):\n",
    "    attribute, scores = [], []\n",
    "    ranking = np.argsort(ratings)\n",
    "\n",
    "    for k in np.arange(len(ranking)):\n",
    "        attribute.append(items[ranking[k]])\n",
    "        scores.append(ratings[ranking[k]])\n",
    "\n",
    "    return attribute, scores\n",
    "\n",
    "def convert(data, nb_users, nb_movies):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MoviesLens - Exploration des données\n",
    "\n",
    "Les données que nous allons manipuler afin d'explorer différents algorithmes de systèmes de recommendation sont celles associées au projet MovieLens (https://grouplens.org/datasets/movielens/). Brièvement, les données utilisées consistent ici en plus ou moins 100 000 évaluations de films par 943 utilisateurs. Un ensemble de 1 682 films étaient disponible en visionnement. En plus des 100 000 évaluations à notre disposition, nous avons des informations liées à chacun des usagers de même qu'à chacun des films.\n",
    "\n",
    "Enfin, la base de données est téléchargeable ici: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation et traitement des données associées aux usagers\n",
    "\n",
    "Avant de présenter les statistiques descriptives (ou d'explorer les données) liées à la population étudiée, nous allons dans un premier temps traiter les données associées aux usagers afin de pouvoir plus aisément les utiliser avec les algorithmes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('../data/ml-100k/u.user', sep='|', header=None, engine='python', encoding='latin-1')\n",
    "\n",
    "# age\n",
    "users_age = np.matrix(users.loc[:, 1])\n",
    "\n",
    "# sexe\n",
    "users_sex = np.matrix(users.loc[:, 2])\n",
    "users_sex[users_sex == 'M'] = 0\n",
    "users_sex[users_sex == 'F'] = 1\n",
    "\n",
    "# occupation\n",
    "users_occupation = np.array(pd.read_csv('../data/ml-100k/u.occupation', sep='|', header=None, engine='python', encoding='latin-1').loc[:, 0])\n",
    "users_occupation = np.array(users.loc[:, 3])\n",
    "occupation_matrix = np.zeros((len(users), len(users_occupation[0])))\n",
    "\n",
    "for i in np.arange(len(users)): \n",
    "    i_occupation = users_occupation[i]\n",
    "    \n",
    "    for j in np.arange(len(users_occupation[0])):\n",
    "        if i_occupation == users_occupation[j]:\n",
    "            occupation_matrix[i, j] = 1\n",
    "            break            \n",
    "users_occupation = occupation_matrix\n",
    "\n",
    "# concatenation des differentes donnees sociodemographiques sous forme de liste\n",
    "user_attributes = np.concatenate((users_sex, users_age, users_occupation.T)).T.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous explorons par la suite les différentes statistiques descriptives associées aux usagers. Celles-ci comportent des informations en lien avec l'âge, le sexe et l'occupation de chacun des usagers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation et reformatage des données associées aux films\n",
    "\n",
    "De la même façon, nous allons traiter et explorer les données associées aux films. Pour chacun des 1 682 films, nous disposons du titre, de la date de sortie en Amérique du Nord, de même que les genres auxquels il est associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../data/ml-100k/u.item', sep='|', header=None, engine='python', encoding='latin-1')\n",
    "\n",
    "movie_names = np.array(movies.loc[:, 1])\n",
    "movies_genre = np.matrix(movies.loc[:, 5:])\n",
    "movies_genre_names = np.array(pd.read_csv('../data/ml-100k/u.genre', sep='|', header=None, engine='python', encoding='latin-1').loc[:, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation et reformatage des données associées aux évaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À la base, le jeu de données comporte 100 000 lignes (une évaluation par ligne) où sont respectivement recensés le numéro d'identification de l'utilisateur, le numéro d'identification du film, l'évaluation associée et un marqueur de temps auquel le film a été visionné. Les ensembles d'entrainement et de test ont été fournis tel quel et comportent respectivement 80 et 20 milles évaluations.\n",
    "\n",
    "###### REMARQUE : \n",
    "La notion d'ensembles d'entraînement et de test dans le cadre de système de recommendation est quelque peu différente de ce que l'on voit habituellement dans un cas classique de problème supervisé. Si dans le cadre d'un problème supervisé, l'ensemble de test consiste essentiellement en de nouvelles observations (lire lignes) indépendantes des observations préalablement observées dans l'ensemble d'entrainement, le paradigme est sensiblement différent lorsque nous travaillons avec des systèmes de recommendation.\n",
    "\n",
    "Effectivement, et en raison du modèle mathématique sur lequel est basé les systèmes de recommendation, les données appartenant à l'ensemble de test ne sont pas associées à une nouvelle utilisatrice, mais bien à de nouvelles évaluations, ou des évaluations futures. Dès lors, les données associées aux ensembles d'entrainement, de validation et de test ne sont plus indépendantes tel que supposé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('../data/ml-100k/u1.base', delimiter='\\t')\n",
    "training_set = np.array(training_set, dtype='int')\n",
    "test_set = pd.read_csv('../data/ml-100k/u1.test', delimiter='\\t')\n",
    "test_set = np.array(test_set, dtype='int')\n",
    "\n",
    "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_items = int(max(max(training_set[:, 1]), max(test_set[:, 1])))\n",
    "\n",
    "train_set = convert(training_set, nb_users, nb_items)\n",
    "test_set = convert(test_set, nb_users, nb_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration des données et statistiques descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Créations des sous-ensembles d'entrainement et de validation\n",
    "\n",
    "Enfin, pour obtenir le meilleur modèle, et fixer l'ensemble des paramètres et hyperparamètres optimaux, nous devons construire des sous-ensembles d'entrainement et de validation. Puisque le but de l'atelier n'est pas d'étudier la notion de biais systèmatique associée à la présence de données manquantes dans les systèmes de recommendation, nous allons naïvement supposer que chacune des évaluations sont indépendantes les unes des autres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, ratio, tensor=False):\n",
    "\n",
    "    train, valid = np.zeros((len(data), len(data[0]))).tolist(), np.zeros((len(data), len(data[0]))).tolist()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            if data[i][j] > 0:\n",
    "                if np.random.binomial(1, ratio, 1):\n",
    "                    train[i][j] = data[i][j]\n",
    "                else:\n",
    "                    valid[i][j] = data[i][j]\n",
    "\n",
    "    return [train, valid]\n",
    "\n",
    "train = split(train_set, 0.8)\n",
    "\n",
    "train = torch.FloatTensor(train)\n",
    "test = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Système de recommendation basé sur des architectures d'apprentissage profond\n",
    "\n",
    "Mettre commentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "\n",
    "    def __init__(self, ratings, movie_names, criterion):\n",
    "        \n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(len(movie_names), 100)\n",
    "        self.fc2 = nn.Linear(100, len(movie_names))\n",
    "        \n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.movie_names = movie_names\n",
    "        self.ratings = ratings\n",
    "    \n",
    "    def recommendations(self, user_id, top_what=5):\n",
    "        \n",
    "        user_ratings = torch.FloatTensor(self.ratings[user_id])\n",
    "        predictions = self(user_ratings).detach().numpy()\n",
    "\n",
    "        predictions[user_ratings.numpy() != 0] = 0\n",
    "        recommendations = rearrange(self.movie_names, predictions)[0][-top_what:]\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def fit(self, ratings, valid=False):\n",
    "         \n",
    "        nb_users, nb_movies = len(ratings[valid  * 1]), len(ratings[valid  * 1][0])\n",
    "        average_loss, s = 0, 0.\n",
    "        \n",
    "        for id_user in range(nb_users):\n",
    "\n",
    "            input = Variable(ratings[valid  * 1][id_user]).unsqueeze(0)\n",
    "            target = input.clone()\n",
    "\n",
    "            if torch.sum(target > 0) > 0:\n",
    "\n",
    "                output = self(input)\n",
    "                target.require_grad = False\n",
    "                output[target == 0] = 0\n",
    "                loss = self.criterion(output, target)\n",
    "\n",
    "                if not valid:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                average_loss += np.sqrt(loss.data / float(torch.sum(target.data > 0)))\n",
    "                s += 1.\n",
    "        \n",
    "        return average_loss, s\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        h1 = torch.sigmoid(self.fc1(x))\n",
    "        return self.fc2(h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-encodeurs (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paramètres considérés\n",
    "\n",
    "Dans le cas d'un auto-encodeur (AE), plusieurs paramètres pourront considérés. Parmis les plus évidents, mentionnons simplement le nombre de couches cachées et le nombre de neuronnes sur chacune d'elles. Nous pourrons également considérer les différentes fonctions d'activation, ici limité à une seule et consistant à une fonction sigmoïde. \n",
    "\n",
    "Même si typiquement les couches d'entrée et de sortie d'un auto-encodeur sont identiques, nous pouvons utiliser les données sur les utilisateurs afin de prédire avec plus de précision (biais) et d'exactitude (variance). Nous explorerons cet aspect par la suite.\n",
    "\n",
    "D'une grande importance également est le type de la fonction de perte. Si l'erreur quadratique moyenne est majoritairement utilisée, plusieurs autres options existent et la littérature récente semble délaisser l'usage de la MSE et suggérant plutôt d'autres alternatives plus à propos. Plus technique, nous pourrons également considérer comme un paramètre le type d'optimiseur pour effectuer l'estimation des paramètres associés à l'auto-encodeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparamètres considérés\n",
    "\n",
    "Les hyperparamètres considérés sont semblables à ceux utilisés dans les autres architectures en apprentissage profond. À savoir: le pas d'apprentissage (learning rate), le nombre d'époques ou d'itérations, la régularisation (weight decay) imposée sur les paramètres du modèle de même que le critère d'arrêt.\n",
    "\n",
    "En temps normal, la meilleure combinaison des (hyper) paramètres se fera en étudiant leur performance sur l'ensemble de validation.  \n",
    "\n",
    "Une fois l'ensemble des paramètres et hyperparamètres définis, nous pouvons initialiser le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02\n",
    "nb_epoch = 20\n",
    "weight_decay = 0.02\n",
    "stop_crit = 0.002\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "ae = AE(train_set, movie_names, criterion)\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle\n",
    "\n",
    "L'entraînement du modèle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[False * 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "943\n",
      "epoch:  1    |   train:  0.0352    |   valid:  0.0335\n",
      "943\n",
      "943\n",
      "epoch:  2    |   train:  0.031    |   valid:  0.0327\n",
      "943\n",
      "943\n",
      "epoch:  3    |   train:  0.0287    |   valid:  0.032\n",
      "943\n",
      "943\n",
      "epoch:  4    |   train:  0.0274    |   valid:  0.032\n",
      "943\n",
      "943\n",
      "epoch:  5    |   train:  0.0256    |   valid:  0.0313\n",
      "943\n",
      "943\n",
      "epoch:  6    |   train:  0.0245    |   valid:  0.0319\n",
      "943\n",
      "943\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, nb_epoch + 1):\n",
    "    \n",
    "    train_loss, train_s = ae.fit(ratings=train)\n",
    "    valid_loss, valid_s = ae.fit(ratings=train, valid=True)\n",
    " \n",
    "    print('epoch: ', epoch, '   |   train: ', np.around(train_loss.numpy() / train_s, 4), \\\n",
    "          '   |   valid: ', np.around(valid_loss.numpy() / valid_s, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1    |   train:  0.0349    |   valid:  0.0356\n",
      "epoch:  2    |   train:  0.0306    |   valid:  0.032\n",
      "epoch:  3    |   train:  0.0289    |   valid:  0.0314\n",
      "epoch:  4    |   train:  0.028    |   valid:  0.0316\n",
      "epoch:  5    |   train:  0.0263    |   valid:  0.0315\n",
      "epoch:  6    |   train:  0.0248    |   valid:  0.0313\n",
      "epoch:  7    |   train:  0.0237    |   valid:  0.031\n",
      "epoch:  8    |   train:  0.0231    |   valid:  0.0313\n",
      "epoch:  9    |   train:  0.0226    |   valid:  0.0313\n",
      "epoch:  10    |   train:  0.0218    |   valid:  0.0314\n",
      "epoch:  11    |   train:  0.0208    |   valid:  0.0313\n",
      "epoch:  12    |   train:  0.0209    |   valid:  0.0314\n",
      "epoch:  13    |   train:  0.0206    |   valid:  0.0317\n",
      "epoch:  14    |   train:  0.0198    |   valid:  0.0321\n",
      "epoch:  15    |   train:  0.0195    |   valid:  0.0323\n",
      "epoch:  16    |   train:  0.019    |   valid:  0.0325\n",
      "epoch:  17    |   train:  0.0186    |   valid:  0.0328\n",
      "epoch:  18    |   train:  0.0185    |   valid:  0.0331\n",
      "epoch:  19    |   train:  0.0192    |   valid:  0.0333\n",
      "epoch:  20    |   train:  0.0183    |   valid:  0.0335\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, nb_epoch + 1):\n",
    "    \n",
    "    train_loss, valid_loss = 0, 0\n",
    "    s = 0.\n",
    "    \n",
    "    nb_movies = len(movie_names)\n",
    "    \n",
    "    for id_user in range(nb_users):\n",
    "        input_train = Variable(train[0][id_user]).unsqueeze(0)\n",
    "        target_train = input_train.clone()\n",
    "        \n",
    "        input_valid = Variable(train[1][id_user]).unsqueeze(0)\n",
    "        target_valid = input_valid.clone()\n",
    "        \n",
    "        if (torch.sum(target_train > 0) > 0) & (torch.sum(target_valid > 0) > 0):\n",
    "\n",
    "            output_train = ae(input_train)\n",
    "            target_train.require_grad = False  # pourquoi false?\n",
    "            output_train[target_train == 0] = 0\n",
    "\n",
    "            loss_train = criterion(output_train, target_train)\n",
    "\n",
    "            output_valid = ae(input_valid)\n",
    "            target_valid.require_grad = False  # pourquoi false?\n",
    "            output_valid[target_valid == 0] = 0\n",
    "\n",
    "            loss_valid = criterion(output_valid, target_valid)\n",
    "\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += np.sqrt(loss_train.data / float(torch.sum(target_train.data > 0)))\n",
    "            \n",
    "            valid_loss += np.sqrt(loss_valid.data / float(torch.sum(target_valid.data > 0)))\n",
    "            s += 1.\n",
    " \n",
    "    print('epoch: ', epoch, '   |   train: ', np.around(train_loss.numpy() / s, 4), \\\n",
    "          '   |   valid: ', np.around(valid_loss.numpy() / s, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Évaluation finale sur l'ensemble de test\n",
    "\n",
    "Mettre description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(1.3415)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(test[id_user]).unsqueeze(0)\n",
    "    target = Variable(test[id_user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = ae(input)\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data * mean_corrector)\n",
    "        s += 1.\n",
    "print('test loss: ' + str(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des performances générales et visualisation des résultats\n",
    "\n",
    "Visualisation des résultats: parler des prédictions en fonction:\n",
    "1. des attributs de l'utilisateur (sexe, age occupation)\n",
    "2. des genre de films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour un individu choisi\n",
    "\n",
    "\n",
    "Fonction pour effectuer les meilleures recommendations en fonction de certains critères (intégrés dans la classe). Dans un premier temps, nous pouvons suggérer les 'k' meilleures recommendations pour un usager en particulier. Naturellement, les recommendations faites ne suggèrent que des films non visionnés par l'usager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tin Drum, The (Blechtrommel, Die) (1979)',\n",
       " 'Lamerica (1994)',\n",
       " 'Big Sleep, The (1946)',\n",
       " 'For Whom the Bell Tolls (1943)',\n",
       " 'Evil Dead II (1987)']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.recommendations(user_id = 0, top_what = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En s'attardant un peu aux nouvelles recommendations faites, on peut identifier le comportement de l'usager et ses préférences en terme de genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fait, ça pourrait être intéressant de proposer à l'usager des films en fonction de ces préférences du moment en fonction du genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = 'Action'\n",
    "model.predict_instance(user_id, ratings, top_what, genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peut-être même pourrions-nous sonder son inconscient (lire les couches latentes du modèle) et de lui proposer de nouveaux films que lui-même n'imaginait pas aimer. Ces recommendations sont faites au-delà des genres explicitement définis dans le jeu de données initial. Pour plus de détail, voir la section supplément."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations(self, data, id_user, ratings, top_what, movie_names):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des différentes techniques : MF vs AE\n",
    "\n",
    "Présenter discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
