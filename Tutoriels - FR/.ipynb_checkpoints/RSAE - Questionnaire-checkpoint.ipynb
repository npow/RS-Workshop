{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÉCOLE IVADO - SYSTÈMES DE RECOMMANDATION\n",
    "# ÉTÉ 2019 \n",
    "\n",
    "# Auto-encodeur\n",
    "\n",
    "## Auteurs: \n",
    "\n",
    "David Berger (davidberger2785 [at] gmail [dot] com)\n",
    "\n",
    "Laurent Charlin (lcharlin [at] gmail [dot] com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "Dans cet atelier, nous proposons d'implémenter un système de recommandation basé sur un auto-encodeur (AE), une architecture classique en apprentissage profond. Tout comme lors du volet de l'atelier portant sur les modèles utilisant la factorisation matricielle, nous utiliserons la base de données <a href=\"https://grouplens.org/datasets/movielens/\">MovieLens</a> afin d'entraîner nos modèles, mener certaines expériences et comparer nos résultats avec d'autres types d'architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Installation des librairies\n",
    "\n",
    "Avant de commencer, nous devons nous assurer d'installer les librairies nécessaires pour le tutoriel à l'aide de `pip`.  Pour ce faire, exécutez la cellule suivante en la sélectionnant et en cliquant `shift`+`Enter`. Ceci peut prendre quelques minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous importons par la suite les librairies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "# regroupement des fonctions maisons\n",
    "import utilities as utl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Jeu de données - MoviesLens 100k\n",
    "\n",
    "Nous pouvons télécharger les données préalablement traitées lors de l'atelier précédent avec la librairie <a href=\"https://docs.python.org/2/library/pickle.html\"> `Pickle`</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = pickle.load(open('../data/saves/users', 'rb'))\n",
    "user_attributes = pickle.load(open('../data/saves/user_attributes', 'rb'))\n",
    "movies = pickle.load(open('../data/saves/movies', 'rb'))\n",
    "\n",
    "train_set = pickle.load(open('../data/saves/train', 'rb'))\n",
    "test_set = pickle.load(open('../data/saves/test', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Système de recommandation: Auto-encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 L'apprentissage profond avec Pytorch\n",
    "\n",
    "Afin de construire un système de recommandation basé sur les AE, nous allons utiliser la librairie \n",
    "<a href=\"https://pytorch.org/\"> `Pytorch`</a>.  Cette libraire fournit deux fonctionnalités extrêmement intéressantes:\n",
    "<ul>\n",
    "<li> Manipulation de tenseurs (matrices à plusieurs dimensions) permettant d'effectuer les calculs avec GPU.</li>\n",
    "<li> Utilisation de la différentiation automatique avec la classe <a href=\"http://pytorch.org/docs/master/autograd.html\"> autograd</a> permettant de calculer facilement la descente de gradient. </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque nous travaillerons avec Pytorch, transformons les données de MoviesLens en objet tensoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.FloatTensor(train_set)\n",
    "train, valid = train[0], train[1]\n",
    "test = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**! Remarque !** \n",
    "\n",
    "Bien que la documentation disponible pour Pytorch soit détaillée (comparativement à d'autres librairies en apprentissage profond), il est facile de s'y perdre. N'empêche, pour la suite de l'atelier, il n'est pas nécessaire de saisir la totalité des nuances associées aux différentes commandes. En fait, l'essentiel est plutôt de bien saisir les tenants et aboutissants des étapes clés présentées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Implémentation\n",
    "\n",
    "Nous pouvons décliner en cinq étapes l'implémentation d'un AE comme système de recommandation:\n",
    "\n",
    "1. Initialisation de l'AE,\n",
    "2. Propagation message,\n",
    "3. Estimation:  calcul du coût et rétro propagation,\n",
    "4. Boucle d'apprentissage,\n",
    "5. Évaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Initialisation\n",
    "\n",
    "Dans un premier temps, nous définissons la classe de l'auto-encodeur à l'aide de la classe <a href=\"http://pytorch.org/docs/master/nn.html#module\">torch.nn.Module</a>. En PyTorch, tout réseau de neurones doit hériter de cette classe. La classe d'auto-encodeur que nous définierons fait appel à d'autres classes communes dans Pytorch, telle <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Linear\">torch.nn.Linear(in_features, out_features)</a>. Cette dernière  implémente une couche linéaire (comme son nom l'indique) et complétement connectée prenant par défaut deux paramètres, soit l'entrée (in_features) et la sortie (out_features).  \n",
    "\n",
    "##### Question 1\n",
    "\n",
    "1. Complétez l'initialisation de la classe d'auto-encodeur conformément au schéma de l'architecture présenté ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, inputs, outputs, features, criterion=None):\n",
    "        \n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        # Complétez ici\n",
    "        # Et là\n",
    "        \n",
    "        self.criterion = criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe maintenant définie, nous définierons:\n",
    "\n",
    "1. Le nombre de neurones en entrée,\n",
    "2. Le nombre de neurones en sortie,\n",
    "3. Le nombre de neuronnes désirés dans la couche cachée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2\n",
    "\n",
    "1. Initialisez l'auto-encodeur avec les bonnes valeurs de paramètres.\n",
    "2. Est-ce pertinent que la couche cachée ait plus de neurones que la couche d'entrée?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_inputs = ?\n",
    "nb_outputs = ?\n",
    "nb_features = ?\n",
    "\n",
    "# Ininitalisation \n",
    "ae = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Propagation\n",
    "\n",
    "Lors de la phase de propagation, la fonction `forward` associée à la propagation du message définit les opérations à effectuer afin de calculer les éléments de la sortie. Cette fonction est indispensable, porte par défault le nom `forward` et doit concorder avec l'initialisation du modèle lors de l'étape précédente afin de permettre une rétropropagation adéquate.\n",
    "   \n",
    "Notons également l'utilisation de la méthode <a href=\"http://pytorch.org/docs/master/nn.html#torch-nn-functional\">torch.nn.functional</a> définissant un ensemble de fonctions qui peuvent être appliquées aux couches d'un réseau de neurones. Dans le cadre de cet atelier, nous utiliserons des fonctions non-linéaires comme <a href=\"http://pytorch.org/docs/master/nn.html#id36\">sigmoid</a> et des fonctions de coût tel l'erreur quadratique moyenne <a href=\"http://pytorch.org/docs/master/nn.html#mse-loss\">mse_loss</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3\n",
    "\n",
    "1. Complétez la fonction `forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, x):\n",
    "    \n",
    "    return ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Estimation des poids\n",
    "\n",
    "Bien que les réseaux de neurones présentent notamment dans capacités prédictives ahurissantes, la complexité de leur archicture peut s'avérer rapidement très grande. D'un point de vue calculatoire, cela se traduit entre autres choses par l'impossibilité d'obtenir un optimum global pour la fonction de coût et bien sûr, d'estimer la valeur des poids de façon analytique, comme cela peut être fait dans un modèle linéaire sous hypothèse de normalité. N'empêche, si aucun optimum global n'est garanti, et si accessoirement aucune forme analytique ne peut être calculée, il n'en demeure pas moins que les poids associés peuvent être estimés. \n",
    "\n",
    "En ce sens, la descente (stochastique) du gradient (et ses dérivées) est une technique d'optimisation efficace et largement mise de l'avant en apprentissage profond. Cette technique fait appel à trois concepts clés, soit:\n",
    "\n",
    "1. La fonction de coût.\n",
    "2. Le type d'optimisateur.\n",
    "3. La rétropropagation du gradient (implémentée dans la boucle d'apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.1 Fonction de coût\n",
    "\n",
    "Comme nous l'avons vu lors du précédent atelier, la fonction de coût joue un rôle déterminant dans la construction d'un modèle prédictif. En effect, c'est cette même fonction de coût que nous essaierons de minimiser (ou maximiser c'est selon) en ajustant itérativement les poids de l'AE au fur et à mesure que nous lui fournirons des évaluations. Ainsi, deux fonctions de coût différentes entraîneront fort probablement deux modèles différents. Comme d'habitude, Pytorch propose une grande quantité  de <a href=\"http://pytorch.org/docs/master/nn.html#id42\"> fonctions de coût</a> que vous pourrez explorer à votre guise.\n",
    "\n",
    "Dans la mesure où l'on considère que les évaluations varient entre 1 et 5, l'erreur quadratique moyenne (EQM) semble une première option intéressante. Formellement, dans le cadre d'un système de recommandation, nous définierons l'EQM ainsi : \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "EQM (\\mathbf{R}, \\hat{\\mathbf{R}}) = \\frac{1}{n} \\sum_{r_{ui} \\neq 0} (r_{ui} - \\hat{r}_{ui})^2, \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "où $\\mathbf{R}$ et $\\hat{\\mathbf{R}}$ sont respectivement les matrices des évaluations observées et prédites, $n$ est le nombre total d'estimations effectuées. De la même façon, $r_{ui}$ et $\\hat{r}_{ui}$ sont des scalaires associés respectivement à l'évaluation observée et l'évaluation estimée de l'usager $u$ pour l'item $i$.\n",
    "\n",
    "Puisque nous avons codé la fonction de coût comme étant un attribut de la classe des auto-encodeurs, nous pouvons la définir avec la commande suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4\n",
    "\n",
    "1. Si l'EQM nous semble une fonction de coût intéressante dans le cas de système de recommandation avec des données explicites, quelle fonction de coût pertinente aurait pu être implémentée si les données avaient été implicites (évaluations binaires en fonction des préférences)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.2 Optimiseur\n",
    "\n",
    "PyTorch fournit plusieurs <a href=\"http://pytorch.org/docs/master/optim.html#algorithms\"> méthodes d'optimisation</a> plus ou moins dérivées de la descente du gradient via la classe `torch.optim`. Parmi ces techniques, nommons: \n",
    "<ul>\n",
    "<li> SGD (Descente Stochastique du Gradient) : implémentation de SGD.\n",
    "<li> Adam (Adaptive Moment Estimation) : variation de la méthode de descente de gradient où le taux d'apprentissage est ajusté pour chaque paramètre.     \n",
    "<li> RMSprop : fonction de coût adaptée aux systèmes de recommandations. Plus de détails <a href=\"http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf\">ici</a>.\n",
    "</ul>\n",
    "\n",
    "Dans tous les cas, lorsque nous utilisons des méthodes d'optimisation itératives, nous devons fournir un pas d'apprentissage (learning rate) et une contrainte sur les poids, pour des raisons similaires à celles évoquées lors du précédent atelier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02\n",
    "weight_decay = 0.2\n",
    "\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.3 Rétropropagation du gradient\n",
    "\n",
    "En Pytorch, la rétropropagation du gradient est simplifiée grâce à la différentiation automatique du gradient et de la classe <a href=\"http://pytorch.org/docs/master/notes/autograd.html\">autograd</a>. Celle-ci se fait en deux temps:\n",
    "\n",
    "1. Calcul de la fonction de coût avec la fonction définie au préalable dans la classe de l'AE.\n",
    "2. Dérivation automatique de la fonction de coût grace à la fonction `backward()`.\n",
    "\n",
    "L'ensemble du processus de rétropropagation est directement implémenté dans la boucle d'apprentissage définie ci-dessous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Boucle d'apprentissage\n",
    "\n",
    "Lorsqu'un auto-encodeur (et de façon générale une architecture basée sur l'apprentissage profond) est utilisé comme système de recommandation, la boucle d'apprentissage diffère quelque peu de celle associée aux modèles basés sur la factorisation matricielle. Ainsi, chaque évaluation n'est plus considérée de façon individuelle, comme c'était le cas auparavant, mais est ici considérée sur l'ensemble des évaluations fournies par un individu donné par exemple.\n",
    "\n",
    "##### Question 5\n",
    "\n",
    "1. Complétez la phase de propagation.\n",
    "2. À la fin de chaque époque, quelle statistique serait-il préférable de calculer? Codez-la. Remarque : il est préférable d'initialiser des objets en début de fonction (voir ligne 6)\n",
    "3. Implémentez la phase de rétropropagation.\n",
    "4. Dans la mesure où des données issues de l'ensemble d'entraînement, de validation ou de test peuvent être utilisées dans la fonction fit, quelles condition devrions-nous mettre à la ligne 22?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, x, y, valid=False):\n",
    "    \n",
    "    nb_obs, nb_items = len(x), len(x[0])\n",
    "    average_loss, s = 0, 0.\n",
    "\n",
    "    for id_user in range(nb_obs):\n",
    "\n",
    "        inputs = Variable(x[id_user]).unsqueeze(0)\n",
    "        target = Variable(y[id_user]).unsqueeze(0)\n",
    "\n",
    "        if torch.sum(target > 0) > 0:\n",
    "            \n",
    "            # Question 5.1: Phase de propagation\n",
    "            #estimate = ?\n",
    "            #\n",
    "            target.require_grad = False\n",
    "            \n",
    "            # Question 5.3: Phase de rétropropagation\n",
    "            loss = model.criterion(estimate, target)\n",
    "            \n",
    "            # Question 5.4: Condition\n",
    "            if ?:\n",
    "                #loss.backward()\n",
    "                #optimizer.step()\n",
    "\n",
    "            # Question 5.2: Statistique à calculer\n",
    "            #\n",
    "            s += 1.\n",
    "\n",
    "    return model, average_loss, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Entraînement de l'AE\n",
    "\n",
    "L'auto-encodeur et les fonctions associées maintenant implémentés, nous pouvons commencer à entraîner le modèle. Encore une fois, le but ici n'est pas d'ajuster les paramètres de façon telle à obtenir le meilleur modèle possible, mais simplement de comprendre le rôle que ceux-ci peuvent jouer en fonction de leur capacité prédictive. \n",
    "\n",
    "##### Question 6\n",
    "\n",
    "1. Finissez d'implémenter la phase d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 20\n",
    "\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    \n",
    "    # ...\n",
    "    \n",
    "    print('epoch: ', epoch, '   |   train: ', np.around(train_loss.numpy() / train_s, 4), \\\n",
    "          '   |   valid: ', np.around(valid_loss.numpy() / valid_s, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant manipuler les différents paramètres et hyperparamètres de l'AE. Parmi les différentes modifications que vous pouvez apporter, voici une (courte et non exhaustive) liste des modifications facilement implémentables:\n",
    "\n",
    "1. Changer les hyperparamètres (un peu plate).\n",
    "2. Augmenter la taille de la couche cachée (plus intéressant).\n",
    "3. Ajouter des couches cachées au modèle en prenant soin de bien les initialiser et d'adapter la fonction forward.\n",
    "4. Dichotomiser les données à l'aide d'un seuil (par exemple 3) et rouler l'ensemble du code en adaptant ou pas la fonction de coût tel que discuté précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous pouvons évaluer les performances de notre modèle sur l'ensemble test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae, test_loss, test_s = fit(model=ae, x=test, y=test, valid=True)\n",
    "print('test: ', np.around(test_loss.numpy() / test_s, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Analyse\n",
    "\n",
    "\n",
    "### 2.5.1 Exploration de la couche latente\n",
    "\n",
    "De façon analogue à ce qui a été présenté dans l'atelier sur la factorisation matricielle, nous pouvons explorer la couche latente de l'AE. Dans la mesure où la couche d'entrée représente l'ensemble des évaluations pour un individu donnée, chaque neurone de la couche latente sera associé à un attribut latent d'un individu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train\n",
    "model = ae\n",
    "hidden = torch.sigmoid(model.fc1(x)).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que cette information nous semble informe, nous pourrions nous intéresser, par exemple, aux mesures d'association entre les différentes couches cachées, ou encore une couche cachée et une des caractéristiques sociodémographiques. Pour ce faire, une avenue intéressante serait de simplement calculer les corrélations associées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premièrement, en explorant simplement les corrélations entre les différents neurones.\n",
    "\n",
    "##### Question 7\n",
    "\n",
    "1. Quel neurone de la couche cachée vous semble <i>a priori</i> le plus intéressant? Pourquoi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(np.array(hidden))\n",
    "\n",
    "f = plt.figure(figsize=(6, 6))\n",
    "plt.matshow(df.corr(), fignum=f.number)\n",
    "plt.xticks(range(df.shape[1]), df.columns, fontsize=10, rotation=0)\n",
    "plt.yticks(range(df.shape[1]), df.columns, fontsize=10)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>!!! À FINIR !!!\n",
    "\n",
    "Par après, en étudiant les corrélations entre un neurone de la couche cachée et les variables sociodémographiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_hidden = 5\n",
    "df = pd.DataFrame(np.concatenate((np.matrix(hidden[:, id_hidden]).T, np.array(user_attributes)), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 8\n",
    "\n",
    "1. L'étude de la couche latente s'est faite ici en fonction des utilisateurs du système. Serait-il possible d'étudier les couches latentes associées aux individus. Si oui, comment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Applications\n",
    "\n",
    "L'un des objectifs premier des systèmes de recommandation est d'effectuer de recommandations (!) personnalisées pour chacun des utilisateurs. Dès lors, il pourrait être intéressant d'étudier les recommandations effectuées par notre modèle pour un individu spécifique. Il serait également préférable que les recommendations faites ne suggèrent que des films non visionnés par l'usager.\n",
    "\n",
    "##### Question 9\n",
    "\n",
    "1. Implémentez une courte fonction afin d'effectuer les <i>k</i> meilleures recommandations de films n'ayant pas encore été visionnés pour un usager choisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations(model, data, titles, k):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appel de la fonction avec quelques manipulations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 0\n",
    "k=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous l'avons vu lors de l'atelier portant sur les systèmes de recommandation basés sur la factorisation matricielle, nous pouvons facielement personnaliser les algorithmes en fonction de plusieurs paramètres. À titre d'exemple, nous pourrions implémenter un systèmes proposant les meilleures recommandations en fonction:\n",
    "\n",
    "1. D'un genre de film en particulier.\n",
    "2. D'une préférence minimale souhaitée: un score minimal prédit strictrement supérieur à 4,5 par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 10\n",
    "\n",
    "1. Est-ce que les recommandations faites pour un même usager sont les mêmes d'un algorithme à l'autre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Autres idées de modélisations\n",
    "\n",
    "Jusqu'à présent, nous n'avons considéré que les évaluations dans notre modèle. Il pourrait être intéressant de considérer d'autres types de modélisations. \n",
    "\n",
    "Par exemple, au lieu d'utiliser les évaluations de films fait par un individu comme couche d'entrée (donc 1682 neurones), nous pourrions utiliser les évaluations des individus pour un film en particulier (et donc 943 neurones en couches d'entrée). Dans la même veine, à cette modélisation, nous pourrions incorporer les différents genre des films et/ou leur année de sortie.\n",
    "\n",
    "Enfin, nous pourrions simplement nous détacher des auto-encodeurs et lorgner d'autres types d'architectures. En considérant les différentes fonctions et classe précédement codées, nous pourrions implémenter un perceptron multicouche. Pour ce faire, les entrées du réseaux seraient exactement les mêmes, à la différence que les cibles ne seraient constituées que de films non visionnés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Utilisation des données sociodémographiques\n",
    "\n",
    "Il pourrait être intéressant de vérifier si l'utilisation des données sociodémographiques des usagers améliore ou non les capacités prédictives du modèle. En fait, dans la mesure où pareilles informations n'amélioreraient que très peu les capacités du modèle, elles pourraient être utiles lorsqu'un nouvel usager compte utiliser le système de recommandation mis en place. Bien qu'imparfaites, les informations associées à l'âge, le genre et l'occupation d'un usager pourraient être utiles pour présenter les premières recommendations.\n",
    "\n",
    "Afin d'observer comment le SR se comporte avec de telles données, nous devons dans un premier temps modifier les différents ensembles afin que ceux-ci présentent les informations sociodémographiques de chaque usager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.FloatTensor(utl.inner_concatenation(user_attributes, train_set[0]))\n",
    "train_outputs = torch.FloatTensor(train_set[0])\n",
    "\n",
    "valid_inputs = torch.FloatTensor(utl.inner_concatenation(user_attributes, train_set[1]))\n",
    "valid_outputs = torch.FloatTensor(train_set[0])\n",
    "\n",
    "test_inputs = torch.FloatTensor(utl.inner_concatenation(user_attributes, test_set))\n",
    "test_outputs = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 11\n",
    "\n",
    "1. Initialisez l'auto-encodeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 12\n",
    "\n",
    "1. Implémentez la phase d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 13\n",
    "\n",
    "1. Calculez les performances sur l'ensemble test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Problème du démarrage à froid\n",
    "\n",
    "En fait, et tel que mentionné précédemment, au-delà d'améliorer les performances du modèle en fonction de la métrique choisie, l'incorporation de variables sociodémographiques dans le modèle permet d'effectuer des recommandations à un nouvel utilisateur simplement en fonction de ses attributs. Cette modélisation permet de contrecarrer le problème de démarrage à froid ou mieux connu sous le nom de <i>cold start</i>.\n",
    "\n",
    "##### Question 13\n",
    "\n",
    "1. Fixer l'âge, le genre et l'occupation d'un individu.\n",
    "2. Considérer que ce-dernier n'a encore évaluer aucun film.\n",
    "3. Présentez-lui, selon le modèle estimée, les meilleures recommandations de films.\n",
    "4. Faites varier les attributs de l'individus.\n",
    "5. Que remarquez-vous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 13.1: Fixez les attributs d'un individu\n",
    "age = [10]\n",
    "gender = [1]\n",
    "\n",
    "occupation = np.zeros(len(occupation_name))\n",
    "occupation_name = np.array(pd.read_csv('../data/ml-100k/u.occupation', \n",
    "                                            sep='|', header=None, engine='python', encoding='latin-1').loc[:, 0])\n",
    "\n",
    "occupation[occupation_name.tolist().index('artist')] = 1\n",
    "\n",
    "# Question 13.2: Aucun film\n",
    "\n",
    "\n",
    "# Question 13.3: Meilleures recommandations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
